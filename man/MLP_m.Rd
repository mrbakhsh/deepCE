% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/MLP_m.R
\name{MLP_m}
\alias{MLP_m}
\title{Predict Interactions using Multi-layer Perception (MLP)}
\usage{
MLP_m(
  data,
  train_d,
  train_l,
  nlayers = 2,
  powerto1 = 6,
  powerto2 = 5,
  drate = 0.1,
  optimizer = "rmsprop",
  epochs = 50,
  b_size = 128,
  cv_fold = 5,
  plots = FALSE,
  filename = "plots.pdf"
)
}
\arguments{
\item{data}{A matrix containing concatenated co-elution profiles,
generated from \code{\link{getPPI}}.}

\item{train_d}{A matrix of training data containing numerical features,
generated from \code{\link{build_trainingData}}.}

\item{train_l}{A vector of binary categorical label (0-1),
generated from \code{\link{build_trainingData}}.}

\item{nlayers}{Number of hidden layers. Defaults to 2.}

\item{powerto1}{Integer, the number of neurons in the first hidden layer
as defined by two to the power of this value.Defaults to 6.}

\item{powerto2}{Integer, the number of neurons in the subsequent hidden
layer as defined by two to the power of this value. Defaults to 7.}

\item{drate}{Numeric, the dropout rates range. Defaults to 0.1.}

\item{optimizer}{Name of the optimizee. For most models,
this defaults to "rmsprop".}

\item{epochs}{Number of epochs to train the model. Defaults to 50.}

\item{b_size}{Number of samples per gradient update. Defaults to 128.}

\item{cv_fold}{Number of partitions for cross-validation; defaults to 5.}

\item{plots}{Logical value, indicating whether to plot the performance of
the learning algorithm using k-fold cross-validation; defaults to FALSE.
\itemize{ \item{pr_plot} - Precision-recall plot
\item{roc_plot} - ROC plot
\item{radar_plot} - Radar plot showing
accuracy, F1-score , positive predictive value (PPV), sensitivity (SE)
and MCC.}}

\item{filename}{character string, indicating the output filename as an pdf
object. Defaults to plots.pdf.}
}
\value{
Predicted interactions with predicted scores.
}
\description{
This function uses the feedforward feedforward deep neural
networks (DNN) (aka multi-layer perceptron)  to
predict interactions from co-elution data.
}
\details{
MLP_m
}
\examples{
#load the co-elution data
data("HelaCE")
#load the reference data for training
data("refcpx")
# concatenate the profile
m_combined <- getPPI(HelaCE, similarity_calculation = TRUE)
# build training data
t_data <- build_trainingData(HelaCE, refcpx)
#predict
pred_int <-
MLP_m(m_combined,
t_data$train_d,
t_data$train_l,
cv_fold = 2)
}
\author{
Matineh Rahmatbakhsh, \email{matinerb.94@gmail.com}
}
